{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0f7060e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lxml import etree\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import WordNetLemmatizer\n",
    "from collections import defaultdict\n",
    "import string\n",
    "import re\n",
    "import nltk\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5f3fee6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = etree.parse('data/news.xml')\n",
    "root = tree.getroot()\n",
    "corpus = root[0]\n",
    "\n",
    "wnl = WordNetLemmatizer()\n",
    "data = pd.DataFrame({'Title':[], 'Text':[]})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dad92673",
   "metadata": {},
   "source": [
    "My custom model using tf-idf and parsing the data manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ac33b832",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Brain Disconnects During Sleep:\n",
      "sleep cortex consciousness tononi activity \n",
      "\n",
      "New Portuguese skull may be an early relative of Neandertals:\n",
      "skull fossil europe year trait \n",
      "\n",
      "Living by the coast could improve mental health:\n",
      "health mental coast research living \n",
      "\n",
      "Did you knowingly commit a crime? Brain scans could tell:\n",
      "brain study wa suitcase result \n",
      "\n",
      "Computer learns to detect skin cancer more accurately than doctors:\n",
      "dermatologist skin melanoma year cnn \n",
      "\n",
      "US economic growth stronger than expected despite weak demand:\n",
      "u quarter ha year rate \n",
      "\n",
      "Microsoft becomes third listed US firm to be valued at $1tn:\n",
      "microsoft share cloud market ha \n",
      "\n",
      "Apple's Siri is a better rapper than you:\n",
      "siri wa time rhyme ha \n",
      "\n",
      "Netflix viewers like comedy for breakfast and drama at lunch:\n",
      "netflix show day comedy viewer \n",
      "\n",
      "Loneliness May Make Quitting Smoking Even Tougher:\n",
      "smoking loneliness study smoke quit \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for news in corpus:\n",
    "    title = news[0].text\n",
    "    text = news[1].text\n",
    "    \n",
    "    text_tokenized = word_tokenize(text.lower())\n",
    "    text_lemmatized = [wnl.lemmatize(word) for word in text_tokenized]\n",
    "    text_lemmatized = [wnl.lemmatize(word) for word in text_lemmatized if word not in stopwords.words('english')]\n",
    "    punct = f'^[{re.escape(string.punctuation)}]+$'\n",
    "    no_punctuation = [re.sub(punct, '', word) for word in text_lemmatized]\n",
    "    nouns = [word for word in no_punctuation if nltk.pos_tag([word])[0][1] == 'NN'] \n",
    "    data = data.append({'Title': title, 'Text': ' '.join(nouns)}, ignore_index=True)\n",
    "    \n",
    "    words_counter = defaultdict(int)\n",
    "    for word in nouns:\n",
    "        words_counter[word] += 1\n",
    "        \n",
    "    top5 = sorted(words_counter.items(), key=lambda x: (x[1], x[0]), reverse=True)[1:6]\n",
    "    print(title + ':')\n",
    "    for word, count in top5:\n",
    "        print(word, end=' ')\n",
    "        \n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "202e92f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer(input='content')\n",
    "\n",
    "tfidf_matrix = vectorizer.fit_transform(data['Text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1067683a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wojtek/PycharmProjects/Key Terms Extraction/.idea/VirtualEnvironment/lib/python3.8/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "tf_Idf = pd.DataFrame(tfidf_matrix.toarray(), columns=vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1c048aa",
   "metadata": {},
   "source": [
    "The results of sklearn's model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "93342135",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Brain Disconnects During Sleep\n",
      "cortex sleep consciousness tononi communication\n",
      "\n",
      "New Portuguese skull may be an early relative of Neandertals\n",
      "skull europe fossil genus trait\n",
      "\n",
      "Living by the coast could improve mental health\n",
      "health coast mental living household\n",
      "\n",
      "Did you knowingly commit a crime? Brain scans could tell\n",
      "brain suitcase study behavior contraband\n",
      "\n",
      "Computer learns to detect skin cancer more accurately than doctors\n",
      "dermatologist melanoma skin cnn benign\n",
      "\n",
      "US economic growth stronger than expected despite weak demand\n",
      "growth rate quarter economy analyst\n",
      "\n",
      "Microsoft becomes third listed US firm to be valued at $1tn\n",
      "microsoft share cloud market company\n",
      "\n",
      "Apple's Siri is a better rapper than you\n",
      "siri rhyme lyric mc producer\n",
      "\n",
      "Netflix viewers like comedy for breakfast and drama at lunch\n",
      "netflix comedy day breakfast documentary\n",
      "\n",
      "Loneliness May Make Quitting Smoking Even Tougher\n",
      "smoking loneliness smoke lead quit\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    print(data.Title[i])\n",
    "    print(' '.join(tf_Idf.loc[i, :].nlargest(5).index))\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
