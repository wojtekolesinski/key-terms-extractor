{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0f7060e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lxml import etree\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import WordNetLemmatizer\n",
    "from collections import defaultdict\n",
    "import string\n",
    "import re\n",
    "import nltk\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5f3fee6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = etree.parse('data/news.xml')\n",
    "root = tree.getroot()\n",
    "corpus = root[0]\n",
    "\n",
    "wnl = WordNetLemmatizer()\n",
    "data = pd.DataFrame({'Title':[], 'Text':[]})\n",
    "# etree.dump(corpus)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ba0fcc69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
     ]
    }
   ],
   "source": [
    "# print(stopwords.words('english'))\n",
    "\n",
    "# stopwords.ensureloaded()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ac33b832",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Brain Disconnects During Sleep:\n",
      "sleep cortex consciousness tononi activity \n",
      "\n",
      "New Portuguese skull may be an early relative of Neandertals:\n",
      "skull fossil europe year trait \n",
      "\n",
      "Living by the coast could improve mental health:\n",
      "health mental coast research living \n",
      "\n",
      "Did you knowingly commit a crime? Brain scans could tell:\n",
      "brain study wa suitcase result \n",
      "\n",
      "Computer learns to detect skin cancer more accurately than doctors:\n",
      "dermatologist skin melanoma year cnn \n",
      "\n",
      "US economic growth stronger than expected despite weak demand:\n",
      "u quarter ha year rate \n",
      "\n",
      "Microsoft becomes third listed US firm to be valued at $1tn:\n",
      "microsoft share cloud market ha \n",
      "\n",
      "Apple's Siri is a better rapper than you:\n",
      "siri wa time rhyme ha \n",
      "\n",
      "Netflix viewers like comedy for breakfast and drama at lunch:\n",
      "netflix show day comedy viewer \n",
      "\n",
      "Loneliness May Make Quitting Smoking Even Tougher:\n",
      "smoking loneliness study smoke quit \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for news in corpus:\n",
    "    title = news[0].text\n",
    "    text = news[1].text\n",
    "    \n",
    "    text_tokenized = word_tokenize(text.lower())\n",
    "    text_lemmatized = [wnl.lemmatize(word) for word in text_tokenized]\n",
    "    text_lemmatized = [wnl.lemmatize(word) for word in text_lemmatized if word not in stopwords.words('english')]\n",
    "    punct = f'^[{re.escape(string.punctuation)}]+$'\n",
    "    no_punctuation = [re.sub(punct, '', word) for word in text_lemmatized]\n",
    "    nouns = [word for word in no_punctuation if nltk.pos_tag([word])[0][1] == 'NN'] \n",
    "    data = data.append({'Title': title, 'Text': ' '.join(nouns)}, ignore_index=True)\n",
    "    \n",
    "    words_counter = defaultdict(int)\n",
    "    for word in nouns:\n",
    "        words_counter[word] += 1\n",
    "        \n",
    "    top5 = sorted(words_counter.items(), key=lambda x: (x[1], x[0]), reverse=True)[1:6]\n",
    "    print(title + ':')\n",
    "    for word, count in top5:\n",
    "        print(word, end=' ')\n",
    "        \n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ba46a0aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Brain Disconnects During Sleep</td>\n",
       "      <td>scientist insight mystery consciousness fade n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>New Portuguese skull may be an early relative ...</td>\n",
       "      <td>half year  member genus  homo  spread europe a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Living by the coast could improve mental health</td>\n",
       "      <td>sea mental health  household income  study  sc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Did you knowingly commit a crime? Brain scans ...</td>\n",
       "      <td>number year someone bar hinge crime  judge jur...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Computer learns to detect skin cancer more acc...</td>\n",
       "      <td>computer wa human dermatologist skin cancer st...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>US economic growth stronger than expected desp...</td>\n",
       "      <td>u growth month year  threat trade war china bu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Microsoft becomes third listed US firm to be v...</td>\n",
       "      <td>microsoft ha become u company  apple amazon  b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Apple's Siri is a better rapper than you</td>\n",
       "      <td>siri  apple assistant   dictation pizza place ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Netflix viewers like comedy for breakfast and ...</td>\n",
       "      <td>netflix viewer prefer diet comedy breakfast  p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Loneliness May Make Quitting Smoking Even Tougher</td>\n",
       "      <td>harder quit smoking  study  survey thousand  r...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title  \\\n",
       "0                     Brain Disconnects During Sleep   \n",
       "1  New Portuguese skull may be an early relative ...   \n",
       "2    Living by the coast could improve mental health   \n",
       "3  Did you knowingly commit a crime? Brain scans ...   \n",
       "4  Computer learns to detect skin cancer more acc...   \n",
       "5  US economic growth stronger than expected desp...   \n",
       "6  Microsoft becomes third listed US firm to be v...   \n",
       "7           Apple's Siri is a better rapper than you   \n",
       "8  Netflix viewers like comedy for breakfast and ...   \n",
       "9  Loneliness May Make Quitting Smoking Even Tougher   \n",
       "\n",
       "                                                Text  \n",
       "0  scientist insight mystery consciousness fade n...  \n",
       "1  half year  member genus  homo  spread europe a...  \n",
       "2  sea mental health  household income  study  sc...  \n",
       "3  number year someone bar hinge crime  judge jur...  \n",
       "4  computer wa human dermatologist skin cancer st...  \n",
       "5  u growth month year  threat trade war china bu...  \n",
       "6  microsoft ha become u company  apple amazon  b...  \n",
       "7  siri  apple assistant   dictation pizza place ...  \n",
       "8  netflix viewer prefer diet comedy breakfast  p...  \n",
       "9  harder quit smoking  study  survey thousand  r...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "202e92f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer(input='content')\n",
    "\n",
    "tfidf_matrix = vectorizer.fit_transform(data['Text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3d19c6eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.08986384 ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.05102528]\n",
      " ...\n",
      " [0.         0.         0.         ... 0.06444402 0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.06303094 0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]]\n"
     ]
    }
   ],
   "source": [
    "print(tfidf_matrix.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "52b8c91a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wojtek/PycharmProjects/Key Terms Extraction/.idea/VirtualEnvironment/lib/python3.8/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "cortex           0.399146\n",
       "sleep            0.399146\n",
       "consciousness    0.342125\n",
       "tononi           0.228083\n",
       "communication    0.171062\n",
       "Name: 0, dtype: float64"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(tfidf_matrix.toarray(), columns=vectorizer.get_feature_names()).loc[0, :].nlargest(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "1067683a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_Idf = pd.DataFrame(tfidf_matrix.toarray(), columns=vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "93342135",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Brain Disconnects During Sleep\n",
      "cortex sleep consciousness tononi communication\n",
      "\n",
      "New Portuguese skull may be an early relative of Neandertals\n",
      "skull europe fossil genus trait\n",
      "\n",
      "Living by the coast could improve mental health\n",
      "health coast mental living household\n",
      "\n",
      "Did you knowingly commit a crime? Brain scans could tell\n",
      "brain suitcase study behavior contraband\n",
      "\n",
      "Computer learns to detect skin cancer more accurately than doctors\n",
      "dermatologist melanoma skin cnn benign\n",
      "\n",
      "US economic growth stronger than expected despite weak demand\n",
      "growth rate quarter economy analyst\n",
      "\n",
      "Microsoft becomes third listed US firm to be valued at $1tn\n",
      "microsoft share cloud market company\n",
      "\n",
      "Apple's Siri is a better rapper than you\n",
      "siri rhyme lyric mc producer\n",
      "\n",
      "Netflix viewers like comedy for breakfast and drama at lunch\n",
      "netflix comedy day breakfast documentary\n",
      "\n",
      "Loneliness May Make Quitting Smoking Even Tougher\n",
      "smoking loneliness smoke lead quit\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    print(data.Title[i])\n",
    "    print(' '.join(tf_Idf.loc[i, :].nlargest(5).index))\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
